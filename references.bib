@misc{tanwar2024opinebotclassfeedbackreimagined,
      title={OpineBot: Class Feedback Reimagined Using a Conversational LLM}, 
      author={Henansh Tanwar and Kunal Shrivastva and Rahul Singh and Dhruv Kumar},
      year={2024},
      eprint={2401.15589},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2401.15589}, 
}
@misc{friedman2024enhancingstudentfeedbackusing,
      title={Enhancing Student Feedback Using Predictive Models in Visual Literacy Courses}, 
      author={Alon Friedman and Kevin Hawley and Paul Rosen and Md Dilshadur Rahman},
      year={2024},
      eprint={2405.15026},
      archivePrefix={arXiv},
      primaryClass={cs.MM},
      url={https://arxiv.org/abs/2405.15026}, 
}


@article{article1,
author = {Williams, Andrew},
year = {2024},
month = {05},
pages = {473-501},
title = {Delivering Effective Student Feedback in Higher Education: An Evaluation of the Challenges and Best Practice},
volume = {10},
journal = {International Journal of Research in Education and Science},
doi = {10.46328/ijres.3404}
}

@article{Sghir2023,
  title = {Recent advances in Predictive Learning Analytics: A decade systematic review (2012--2022)},
  author = {Sghir, Nabila and Adadi, Amina and Lahmer, Mohammed},
  journal = {Education and Information Technologies},
  volume = {28},
  number = {7},
  pages = {8299--8333},
  year = {2023},
  month = jul,
  doi = {10.1007/s10639-022-11536-0},
  issn = {1573-7608},
  url = {https://doi.org/10.1007/s10639-022-11536-0}
}



@INPROCEEDINGS{8725237,
  author={Uskov, Vladimir L. and Bakken, Jeffrey P. and Byerly, Adam and Shah, Ashok},
  booktitle={2019 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Machine Learning-based Predictive Analytics of Student Academic Performance in STEM Education}, 
  year={2019},
  volume={},
  number={},
  pages={1370-1376},
  keywords={Engineering education;Conferences;Three-dimensional displays;machine learning;STEM education;student academic performance;predictive analytics;accuracy},
  doi={10.1109/EDUCON.2019.8725237}
  }


@misc{edalati2020potentialmachinelearningnlp,
      title={The Potential of Machine Learning and NLP for Handling Students' Feedback (A Short Survey)}, 
      author={Maryam Edalati},
      year={2020},
      eprint={2011.05806},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2011.05806}, 
}

@misc{aryal2021literaturesurveystudentfeedback,
      title={A literature survey on student feedback assessment tools and their usage in sentiment analysis}, 
      author={Himali Aryal},
      year={2021},
      eprint={2109.07904},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2109.07904}, 
}

@article{Nieminen2023,
  title = {Feedback literacy: a critical review of an emerging concept},
  author = {Nieminen, Juuso Henrik and Carless, David},
  journal = {Higher Education},
  volume = {85},
  number = {6},
  pages = {1381--1400},
  year = {2023},
  month = jun,
  doi = {10.1007/s10734-022-00895-9},
  issn = {1573-174X},
  url = {https://doi.org/10.0.1007/s10734-022-00895-9}
}



@Article{bdcc8120187,
AUTHOR = {Almalawi, Ahlam and Soh, Ben and Li, Alice and Samra, Halima},
TITLE = {Predictive Models for Educational Purposes: A Systematic Review},
JOURNAL = {Big Data and Cognitive Computing},
VOLUME = {8},
YEAR = {2024},
NUMBER = {12},
ARTICLE-NUMBER = {187},
URL = {https://www.mdpi.com/2504-2289/8/12/187},
ISSN = {2504-2289},
ABSTRACT = {This systematic literature review evaluates predictive models in education, focusing on their role in forecasting student performance, identifying at-risk students, and personalising learning experiences. The review compares the effectiveness of machine learning (ML) algorithms such as Support Vector Machines (SVMs), Artificial Neural Networks (ANNs), and Decision Trees with traditional statistical models, assessing their ability to manage complex educational data and improve decision-making. The search, conducted across databases including ScienceDirect, IEEE Xplore, ACM Digital Library, and Google Scholar, yielded 400 records. After screening and removing duplicates, 124 studies were included in the final review. The findings show that ML algorithms consistently outperform traditional models due to their capacity to handle large, non-linear datasets and continuously enhance predictive accuracy as new patterns emerge. These models effectively incorporate socio-economic, demographic, and academic data, making them valuable tools for improving student retention and performance. However, the review also identifies key challenges, including the risk of perpetuating biases present in historical data, issues of transparency, and the complexity of interpreting AI-driven decisions. In addition, reliance on varying data processing methods across studies reduces the generalisability of current models. Future research should focus on developing more transparent, interpretable, and equitable models while standardising data collection and incorporating non-traditional variables, such as cognitive and motivational factors. Ensuring transparency and ethical standards in handling student data is essential for fostering trust in AI-driven models.},
DOI = {10.3390/bdcc8120187}
}



@misc{lindsay2024responsibledevelopmentautomatedstudent,
      title={The Responsible Development of Automated Student Feedback with Generative AI}, 
      author={Euan D Lindsay and Mike Zhang and Aditya Johri and Johannes Bjerva},
      year={2024},
      eprint={2308.15334},
      archivePrefix={arXiv},
      primaryClass={cs.CY},
      url={https://arxiv.org/abs/2308.15334}, 
}

@article{Shi_Aryadoust_2024, title={A systematic review of AI-based automated written feedback research}, volume={36}, DOI={10.1017/S0958344023000265}, number={2}, journal={ReCALL}, author={Shi, Huawei and Aryadoust, Vahid}, year={2024}, pages={187–209}} <div></div>




@Article{electronics13183762,
AUTHOR = {Halkiopoulos, Constantinos and Gkintoni, Evgenia},
TITLE = {Leveraging AI in E-Learning: Personalized Learning and Adaptive Assessment through Cognitive Neuropsychology—A Systematic Analysis},
JOURNAL = {Electronics},
VOLUME = {13},
YEAR = {2024},
NUMBER = {18},
ARTICLE-NUMBER = {3762},
URL = {https://www.mdpi.com/2079-9292/13/18/3762},
ISSN = {2079-9292},
ABSTRACT = {This paper reviews the literature on integrating AI in e-learning, from the viewpoint of cognitive neuropsychology, for Personalized Learning (PL) and Adaptive Assessment (AA). This review follows the PRISMA systematic review methodology and synthesizes the results of 85 studies that were selected from an initial pool of 818 records across several databases. The results indicate that AI can improve students’ performance, engagement, and motivation; at the same time, some challenges like bias and discrimination should be noted. The review covers the historic development of AI in education, its theoretical grounding, and its practical applications within PL and AA with high promise and ethical issues of AI-powered educational systems. Future directions are empirical validation of effectiveness and equity, development of algorithms that reduce bias, and exploration of ethical implications regarding data privacy. The review identifies the transformative potential of AI in developing personalized and adaptive learning (AL) environments, thus, it advocates continued development and exploration as a means to improve educational outcomes.},
DOI = {10.3390/electronics13183762}
}


@ARTICLE{10.3389/feduc.2024.1466926,

AUTHOR={Ruiz, Judy Julieth Ramírez  and Sanchez, Ana Dolores Vargas  and Figueredo, Oscar Rafael Boude },

TITLE={Impact of gamification on school engagement: a systematic review},

JOURNAL={Frontiers in Education},

VOLUME={9},

YEAR={2024},

URL={https://www.frontiersin.org/journals/education/articles/10.3389/feduc.2024.1466926},

DOI={10.3389/feduc.2024.1466926},

ISSN={2504-284X},

}


@InProceedings{10.1007/978-981-99-7353-8_12,
author="Larrosa, Manuel
and Wives, Leandro
and Rod{\'e}s, Virginia",
editor="Berrezueta, Santiago",
title="Gamification Strategies as Formative Assessment Methods. A Systematic Review",
booktitle="Proceedings of the 18th Latin American Conference on Learning Technologies (LACLO 2023)",
year="2023",
publisher="Springer Nature Singapore",
address="Singapore",
pages="145--156",
abstract="This article aims to deepen the analysis of gamification strategies as a method to offer feedback in the form of formative assessment for elementary school students (K-12). Gamification is defined as the set of strategies that involve dynamics that recreate game experiences, with the purpose of transmitting specific content, and not only for the pleasure of playing itself. It is considered that the psychological effects that playing generates are very beneficial, since playful environments have great motivating potential and allow fluid exchanges through active roles on the part of their participants. Despite the fact that academic production regarding gamification strategies has been very important in the last decade, studies do not discriminate between the different game elements that are part of gamification, such as leaderboards, levels, rankings, etc. For this reason, this review focuses specifically on one of them: the awarding of medals, to learn more about its effects. Beyond its benefits, the incorporation of these practices also supposes a great challenge, which is the need for evaluation that education systems demand. In response to these topics, a systematic review of the literature covering the period 2011--2020 is proposed, specifically delving into the link between: gamification strategies in formal education environments and the implementation of formative assessment methods through gamification by badges.",
isbn="978-981-99-7353-8"
}

